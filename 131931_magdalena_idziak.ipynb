{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maagdaidziak/ADN/blob/main/131931_magdalena_idziak.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Wstęp"
      ],
      "metadata": {
        "id": "MqktrpNysSYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "W projekcie podjęłam się predykcji cen mieszkań na wynajem w Poznaniu (nick na Kaggle Magdalena Idziak, wynik 112342.75),\n",
        "\n",
        "Brakujące dane zaimputowałam na postawie tekstu z innych kolumna (np. liczbę pokoi, dzielnicę z tytułu ogłoszenia), metodą knn, oraz średniej. Dla danych typu bool brakujące kolumny uzupełniłam jako FALSE.\n",
        "\n",
        "Następnie do predykcji najlepszą metodą okazała się optymalizacja Bayesa (BayesSearchCV), która jest alternatywą dla Grid Search przy szukaniu optymalnych parametrów w XGBoost.\n",
        "\n",
        "Przy pisaniu kodu korzystałam z czatu GPT, jednak pomagał on w pisaniu małych fragmentów kodu. W moim doświadczeniu czat najlepiej radzi sobie z małymi zadaniami, które następnie trzeba włączyć do własnego programu.\n"
      ],
      "metadata": {
        "id": "e59FNoL8Zz2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Metodyka"
      ],
      "metadata": {
        "id": "EBlQQGYfsSS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Program składa się z 3 głównych części: main, preprocess_data i train_model_bayes_search (oraz nieużyty finalnie train_model, który używał GridSearcha. Poniżej opisałam co zawiera każda część.\n",
        "\n",
        "\n",
        "2. Przetwarzanie danych:\n",
        "\n",
        "- Dodanie kolumny roku na podstawie 'date_active'.\n",
        "\n",
        "- Poprawienie typów danych na prawidłowe (object na bool), zamiana brakujących i nieprawidłowych wartości (np liczba pokoi <1, liczba metrów <0) na np.nan.\n",
        "\n",
        "- W kolumnach o typie danych \"bool\" zaimputowanie \"FALSE\" dla wszystkich brakujących wartości.\n",
        "\n",
        "\n",
        "- Dla flat_rooms\n",
        "  - imputacja wartości \"1\"  dla rekordów z \"kawale*\" w opisie.\n",
        "\n",
        "  - Imputacja  flat_rooms na podstawie ad_title (rekordy z fragmentem \"pokoj*\") przy pomocy biblioteki \"re\" funkcji extract_room_count.\n",
        "\n",
        "  - Imputacja flat_rooms dla rekordów z flat_area > 0 na podstawie knn = 3 z flat_area.\n",
        "\n",
        "  - Imputacja średnią dla pozostałych braków w flat_rooms.\n",
        "\n",
        "- Dla flat_area:\n",
        "  - Imputacja metodą knn = 3 na podstawie flat_rooms. Założenie, że mieszkania o tej samej liczbie pokoi mogą mieć podobną wielkość.\n",
        "\n",
        "- Dla quarter:\n",
        "   - Imputacja brakującej kolumny quarter na podstawie ad_title. Jeżeli ad_title zawiera słowo należace do zbioru dzielnic z kolumny quarter, imputujemy je.\n",
        "\n",
        "   - Dla pozostałych dzielnic, imputacja dzielnicy \"inne\"\n",
        "\n",
        "\n",
        "3. Trenowanie modelu:\n",
        "\n",
        "- Najpierw użyłam funkcji liniowej.\n",
        "- Następnie Decision Tree i Random Forest przy pomocy Grid Search z pliku train_model.\n",
        "- Następnie użyłam Random Search, który jest szybszy w szukaniu najlepszych parametrów od Grid Search\n",
        "- Ostatecznie wybrałam BayesSearchCV (funkcja znajduje się w pliku train_model_bayes_search), który okazał się najlepszy w szukaniu optymalnych parametrów, jednak wyszukanie ich zabiera dużo czasu.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u0ntTzfwv2rd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Wyniki"
      ],
      "metadata": {
        "id": "vlUj41SlsSNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trenowanie modelu i 10 predykcji. Wyniki zależały od sposobu imputacji danych i wybranego modelu. W nawiasach podałam wyniki MSE dla pliku train.\n",
        "\n",
        "1. Funkcja Liniowa (182225.62) dla\n",
        "        'flat_area', 'flat_rooms', 'year_activ'\n",
        "\n",
        "Imputacja flat_rooms z knn flat_area w przypadku rekordów z flat_area>0. Dla reszty średnia.\n",
        "Flat_area imputowane przy pomocy knn z flat_rooms.\n",
        "\n",
        "2. Grid Search dla\n",
        "        'flat_area', 'flat_rooms', 'year_activ'\n",
        "- Decision Tree (164590.03)\n",
        "- Random Forest (156813.83) dla parametrów: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
        "\n",
        "3. Imputacja flat_rooms z ad_title (kawale* i regex dla większej liczby pokoi).\n",
        "Dla reszty rekordów flat_rooms ze średniej.\n",
        "Imputacja flat_area z knn flat_rooms.\n",
        "\n",
        "4. Dodanie kolumny 'year_active' z 'date_active'. Uwzględnienie jej w budowaniu modelu.\n",
        "\n",
        "4. Random Search - najlepszy wynik (109019.76) dla Random Forest dla parametrów.\n",
        "Dodanie\n",
        "        'flat_rent', 'flat_deposit', 'flat_for_students', 'building_floor_num', 'flat_balcony', 'flat_utility_room', 'flat_garage',\n",
        "        'flat_basement', 'flat_garden', 'flat_tarrace', 'flat_lift', 'flat_two_level', 'flat_kitchen_sep',\n",
        "        'flat_air_cond', 'flat_nonsmokers', 'flat_washmachine', 'flat_dishwasher', 'flat_fridge',\n",
        "        'flat_cooker', 'flat_oven', 'flat_internet', 'flat_television', 'flat_anti_blinds',\n",
        "        'flat_monitoring', 'flat_closed_area'\n",
        "\n",
        "{'max_depth': 22, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
        "\n",
        "5. Imputacja brakujących 'quarter' na podstawie ad_title. Dla reszty rekordów imputacja 'other'. Użycie danych typu dummies.\n",
        "\n",
        "6. BayesSearchCV (XGBoost) w train_model_bayes_search:\n",
        "- Decision Tree: (130202.42)\n",
        "- Random Forest: (86920.66) dla parametrów: {'max_depth': 45, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}"
      ],
      "metadata": {
        "id": "KgyRdKZGY-IF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Podsumowanie"
      ],
      "metadata": {
        "id": "cLjVkczMsSFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Projekt pokazał mi, jak częstym problemem w analizie danych są braki danych. Pozwolił mi również na naukę radzenia sobie z tym problemem.\n",
        "Zauważyłam, że przed analizą i imputacją danych, najpierw konieczne jest bardzo dobre zrozumienie danych i ich kontekstu. Bez tego nie jesteśmy również w stanie efektywnie korzystać z LLMów, które często potzrebują jasnych instrukcji i fragmentowania kodu.\n",
        "Dobre zrozumienie danych, wybranie metod do imputacji, metody budowy modelu i umiejętność korzystania z LLM-ów, umożliwily mi otrzymanie wyniku 112342.75 na Kaggle."
      ],
      "metadata": {
        "id": "RjMW4YQ5ckZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Kody do odtworzenia wyników"
      ],
      "metadata": {
        "id": "y5vxmRoNsc6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "!pip install scikit-optimize # Install the necessary module\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import os\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from skopt import BayesSearchCV\n",
        "\n",
        "#  Funkcja przetwarzania danych\n",
        "def preprocess_data(data, columns_object_dtype, columns_with_conditions):\n",
        "    \"\"\"Przetwarza dane, wypełnia braki i przygotowuje je do modelowania.\"\"\"\n",
        "    data['year_activ'] = pd.to_datetime(data['date_activ'], errors = 'coerce').dt.year\n",
        "    data['year_activ'] = data['year_activ'].fillna(data['year_activ'].mode()[0])\n",
        "\n",
        "\n",
        "    # Zamiana wartości w kolumnie na typ bool\n",
        "    for column in data.select_dtypes(include='object').columns:\n",
        "        if column not in columns_object_dtype:\n",
        "            pd.set_option('future.no_silent_downcasting', True)\n",
        "            data[column] = data[column].fillna(False).astype(bool)\n",
        "\n",
        "    # Zamiana braków danych lub wartości mniejszych od 0\n",
        "    data = data.replace([None, '', 'NA', 'N/A', 'null'], np.nan)\n",
        "    for column, condition in columns_with_conditions.items():\n",
        "        data.loc[condition(data[column]), column] = np.nan\n",
        "\n",
        "    # Sprawdzenie ad_title i imputacja wartości \"1\" w kolumnie \"flat_rooms\" dla kawalerek\n",
        "    data.loc[data['flat_rooms'].isna() & data['ad_title'].str.contains('(?i)kawale', na=False), 'flat_rooms'] = 1\n",
        "\n",
        "    # Sprawdzanie ad_title i imputacja liczby pokoi na podstawie liczby przed \"pok\"\n",
        "    def extract_room_count(title):\n",
        "        match = re.search(r'(\\d)\\s*-?\\s*pok(?:ojowe|oje|\\.|\\s)', title, re.IGNORECASE)\n",
        "        return int(match.group(1)) if match else np.nan\n",
        "\n",
        "    data.loc[data['flat_rooms'].isna(), 'flat_rooms'] = data['ad_title'].apply(\n",
        "        lambda x: extract_room_count(x) if isinstance(x, str) else np.nan)\n",
        "\n",
        "    # Imputacja flat_rooms na podstawie knn z flat_area\n",
        "    mask_missing_rooms = data[\"flat_rooms\"].isna() & (data[\"flat_area\"] > 0)\n",
        "    data_knn_rooms = data[['flat_area', 'flat_rooms']]\n",
        "    imputer = KNNImputer(n_neighbors=3)\n",
        "    data_knn_imputed_rooms = imputer.fit_transform(data_knn_rooms)\n",
        "    data.loc[mask_missing_rooms, \"flat_rooms\"] = data_knn_imputed_rooms[mask_missing_rooms, 1]\n",
        "\n",
        "    # Imputacja średnią dla pozostałych braków w flat_rooms\n",
        "    mean_imputer = SimpleImputer(strategy='mean')\n",
        "    data['flat_rooms'] = mean_imputer.fit_transform(data[['flat_rooms']])\n",
        "\n",
        "    # Imputacja flat_area na podstawie flat_rooms za pomocą KNNImputer\n",
        "    mask_missing_area = data[\"flat_area\"].isna() & (data[\"flat_rooms\"] > 0)\n",
        "    data_knn_area = data[['flat_rooms', 'flat_area']]\n",
        "    imputer_area = KNNImputer(n_neighbors=3)\n",
        "    data_knn_imputed_area = imputer_area.fit_transform(data_knn_area)\n",
        "    data.loc[mask_missing_area, \"flat_area\"] = data_knn_imputed_area[mask_missing_area, 1]\n",
        "\n",
        "\n",
        "    #Imutacja brakujacych wartości w kolumnie 'quarter'\n",
        "    unique_quarters = data['quarter'].dropna().unique()\n",
        "    def extract_quarter_from_title(ad_title):\n",
        "        if isinstance(ad_title, str):\n",
        "            for quarter in unique_quarters:\n",
        "                if str(quarter).lower() in ad_title.lower():\n",
        "                    return quarter\n",
        "        return np.nan\n",
        "    data['quarter'] = data['quarter'].fillna(data['ad_title'].apply(extract_quarter_from_title))\n",
        "    # Imputacja brakujących wartości w kolumnie 'quarter'\n",
        "    data['quarter'] = data['quarter'].fillna('inne')\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "#FUnkcja trenowania modelu\n",
        "def train_and_evaluate_models_with_bayessearch(models_with_params, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"Trenuje modele z BayesSearchCV i ocenia je za pomocą MSE.\"\"\"\n",
        "    results = {}\n",
        "    predictions_dict = {}\n",
        "    for name, (model, search_space) in models_with_params.items():\n",
        "            bayes_search = BayesSearchCV(\n",
        "                estimator=model,\n",
        "                search_spaces=search_space,\n",
        "                scoring='neg_mean_squared_error',\n",
        "                n_iter=20,  # Liczba iteracji optymalizacji\n",
        "                cv=3,\n",
        "                verbose=1,\n",
        "                random_state=42\n",
        "            )\n",
        "            bayes_search.fit(X_train, y_train)\n",
        "            best_model = bayes_search.best_estimator_\n",
        "            predictions = best_model.predict(X_test)\n",
        "            mse = mean_squared_error(y_test, predictions)\n",
        "            results[name] = mse\n",
        "            predictions_dict[name] = predictions\n",
        "            print(f\"{name} - Najlepsze parametry: {bayes_search.best_params_}\")\n",
        "            print(f\"Najlepsze MSE: {-bayes_search.best_score_}\")\n",
        "    return results, predictions_dict\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "\n",
        "    #wczytanie danych do użycia funkcji preprocess_data\n",
        "    train_file_path= 'pzn-rent-train.csv'\n",
        "    test_final_file_path = 'pzn-rent-test.csv'\n",
        "    train_data = pd.read_csv(train_file_path)\n",
        "\n",
        "    # Przygotowanie danych do funkcji preprocess_data\n",
        "    columns_object_dtype = ['ad_title', 'date_activ', 'date_modif', 'date_expire', 'quarter']\n",
        "    columns_with_conditions = {\n",
        "        'flat_area': lambda x: x <= 0,\n",
        "        'flat_rooms': lambda x: x <= 0,\n",
        "        'flat_rent': lambda x: x < 0,\n",
        "        'flat_deposit': lambda x: x < 0\n",
        "    }\n",
        "\n",
        "    #przetworzenie danych (po else) lub pobranie wcześniej przetowrzonego pliku z danymi\n",
        "    modified_train_file = 'pzn-rent-train-modified.csv'\n",
        "    if os.path.exists(modified_train_file):\n",
        "        train_data = pd.read_csv(\"pzn-rent-train-modified.csv\")\n",
        "        print(\"wczytano przetwrzone dane z pliku\")\n",
        "    else:\n",
        "        train_data = preprocess_data(train_data, columns_object_dtype, columns_with_conditions)\n",
        "        train_data.to_csv(modified_train_file, index=False)\n",
        "        print(\"Przetworzono dane i zapisano do pliku.\")\n",
        "\n",
        "    #zamiana danych w kolumnie \"quarter\" na typ dummies\n",
        "    train_data = pd.get_dummies(train_data, columns=['quarter'], drop_first=True)\n",
        "\n",
        "    #przygotowanie cech\n",
        "    additional_features = [\n",
        "        'flat_rent', 'flat_deposit', 'flat_for_students', 'building_floor_num', 'flat_balcony', 'flat_utility_room', 'flat_garage',\n",
        "        'flat_basement', 'flat_garden', 'flat_tarrace', 'flat_lift', 'flat_two_level', 'flat_kitchen_sep',\n",
        "        'flat_air_cond', 'flat_nonsmokers', 'flat_washmachine', 'flat_dishwasher', 'flat_fridge',\n",
        "        'flat_cooker', 'flat_oven', 'flat_internet', 'flat_television', 'flat_anti_blinds',\n",
        "        'flat_monitoring', 'flat_closed_area'\n",
        "    ]\n",
        "    features = ['flat_area', 'flat_rooms', 'year_activ'] + [col for col in train_data.columns if col.startswith('quarter_')] + additional_features\n",
        "    print(\"Wykorzystywane cechy:\", features + additional_features)\n",
        "    target = 'price'\n",
        "    train_data = train_data.dropna(subset=features + [target])\n",
        "    X = train_data[features]\n",
        "    y = train_data[target]\n",
        "\n",
        "    # podział na zbiór treningowy i testowy pliky train_data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Definicja modeli\n",
        "    models_with_params = {\n",
        "         'Decision Tree': (DecisionTreeRegressor(random_state=42), {\n",
        "             'max_depth': (10, 50),\n",
        "             'min_samples_split': (2, 10),\n",
        "             'min_samples_leaf': (1, 5)\n",
        "        }),\n",
        "        'Random Forest': (RandomForestRegressor(random_state=42), {\n",
        "            'n_estimators': (50, 300),\n",
        "            'max_depth': (10, 50),\n",
        "            'min_samples_split': (2, 10),\n",
        "            'min_samples_leaf': (1, 5)\n",
        "        })\n",
        "    }\n",
        "\n",
        "\n",
        "    # Trenowanie modeli\n",
        "    results, predictions = train_and_evaluate_models_with_bayessearch(models_with_params, X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # Porównanie wyników\n",
        "    print(\"Porównanie MSE dla modeli:\")\n",
        "    for model_name, mse in results.items():\n",
        "        print(f\"{model_name}: {mse:.2f}\")\n",
        "\n",
        "    # Wybór najlepszego modelu\n",
        "    best_model_name = min(results, key=results.get)\n",
        "    print(f\"Najlepszy model: {best_model_name} z MSE: {results[best_model_name]:.2f}\")\n",
        "    # Analiza ważności cech dla najlepszego modelu (np. Random Forest)\n",
        "    best_model = models_with_params[best_model_name][0]\n",
        "\n",
        "\n",
        "    # Wczytanie danych testowych i predykcja\n",
        "    test_final_data = pd.read_csv(test_final_file_path)\n",
        "    test_final_data = preprocess_data(test_final_data, columns_object_dtype, columns_with_conditions)\n",
        "    test_final_data = pd.get_dummies(test_final_data, columns=['quarter'], drop_first=True)\n",
        "    test_final_data = test_final_data.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "    final_model = models_with_params[best_model_name][0]\n",
        "    final_model.fit(X_test, y_test)\n",
        "    predicted_prices = final_model.predict(test_final_data)\n",
        "\n",
        "    # Zapis wyników\n",
        "    output_test_final_data = pd.DataFrame({\n",
        "        'ID': range(1, len(predicted_prices) + 1),\n",
        "        'TARGET': predicted_prices\n",
        "    })\n",
        "    output_test_final_data.to_csv('pzn-rent-test-predicted.csv', index=False)\n",
        "    print(\"Predykcja zakończona. Wyniki zapisano w 'pzn-rent-test-predicted.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGIwjfNMeKjd",
        "outputId": "43ae5c81-2773-4f77-b44d-402b28b61ce3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/107.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.1.0 scikit-optimize-0.10.2\n",
            "Przetworzono dane i zapisano do pliku.\n",
            "Wykorzystywane cechy: ['flat_area', 'flat_rooms', 'year_activ', 'quarter_Bajkowe', 'quarter_Biała Góra', 'quarter_Bonin', 'quarter_Centrum', 'quarter_Chartowo', 'quarter_Chwaliszewo', 'quarter_Czekalskie', 'quarter_Dolna Wilda', 'quarter_Dębiec', 'quarter_Edwardowo', 'quarter_Fabianowo', 'quarter_Franowo', 'quarter_Garbary', 'quarter_Grunwald', 'quarter_Górczyn', 'quarter_Górna Wilda', 'quarter_Głuszyna', 'quarter_Główna', 'quarter_Jeżyce', 'quarter_Junikowo', 'quarter_Karolin', 'quarter_Kobyle Pole', 'quarter_Komandoria', 'quarter_Kotowo', 'quarter_Krzesiny', 'quarter_Krzyżowniki', 'quarter_Malta', 'quarter_Marcelin', 'quarter_Marlewo', 'quarter_Minikowo', 'quarter_Morasko', 'quarter_Nadolnik', 'quarter_Naramowice', 'quarter_Naramowickie Osiedle', 'quarter_Nowe Miasto', 'quarter_Ogrody', 'quarter_Ostrów Tumski', 'quarter_Piekary', 'quarter_Piotrowo', 'quarter_Piątkowo', 'quarter_Podolany', 'quarter_Pogodno', 'quarter_Pokrzywno', 'quarter_Raszyn', 'quarter_Rataje', 'quarter_Rynek Jeżycki', 'quarter_Rynek Wildecki', 'quarter_Rynek Łazarski', 'quarter_Smochowice', 'quarter_Sołacz', 'quarter_Stare Miasto', 'quarter_Starołęka', 'quarter_Starołęka Mała', 'quarter_Stary Rynek', 'quarter_Strzeszyn', 'quarter_Strzeszynek', 'quarter_Szczepankowo', 'quarter_Szeląg', 'quarter_Umultowo', 'quarter_Warszawskie', 'quarter_Wilczak', 'quarter_Wilczy Młyn', 'quarter_Wilda', 'quarter_Winiary', 'quarter_Winogrady', 'quarter_Wola', 'quarter_Zawady', 'quarter_Zieliniec', 'quarter_inne', 'quarter_Ławica', 'quarter_Łazarz', 'quarter_Śródka', 'quarter_Świerczewo', 'quarter_Święty Roch', 'quarter_Żegrze', 'flat_rent', 'flat_deposit', 'flat_for_students', 'building_floor_num', 'flat_balcony', 'flat_utility_room', 'flat_garage', 'flat_basement', 'flat_garden', 'flat_tarrace', 'flat_lift', 'flat_two_level', 'flat_kitchen_sep', 'flat_air_cond', 'flat_nonsmokers', 'flat_washmachine', 'flat_dishwasher', 'flat_fridge', 'flat_cooker', 'flat_oven', 'flat_internet', 'flat_television', 'flat_anti_blinds', 'flat_monitoring', 'flat_closed_area', 'flat_rent', 'flat_deposit', 'flat_for_students', 'building_floor_num', 'flat_balcony', 'flat_utility_room', 'flat_garage', 'flat_basement', 'flat_garden', 'flat_tarrace', 'flat_lift', 'flat_two_level', 'flat_kitchen_sep', 'flat_air_cond', 'flat_nonsmokers', 'flat_washmachine', 'flat_dishwasher', 'flat_fridge', 'flat_cooker', 'flat_oven', 'flat_internet', 'flat_television', 'flat_anti_blinds', 'flat_monitoring', 'flat_closed_area']\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10, 5, 10] before, using random point [22, 2, 3]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10, 5, 10] before, using random point [50, 4, 9]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10, 5, 10] before, using random point [46, 2, 4]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Decision Tree - Najlepsze parametry: OrderedDict([('max_depth', 10), ('min_samples_leaf', 5), ('min_samples_split', 10)])\n",
            "Najlepsze MSE: 137392.6768590442\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Random Forest - Najlepsze parametry: OrderedDict([('max_depth', 36), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 300)])\n",
            "Najlepsze MSE: 99875.592578526\n",
            "Porównanie MSE dla modeli:\n",
            "Decision Tree: 123489.47\n",
            "Random Forest: 88176.64\n",
            "Najlepszy model: Random Forest z MSE: 88176.64\n",
            "Predykcja zakończona. Wyniki zapisano w 'pzn-rent-test-predicted.csv'\n"
          ]
        }
      ]
    }
  ]
}